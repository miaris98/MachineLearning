{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearningRestNet50.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T3t2y8T3DEy"
      },
      "source": [
        "**ResNet**-50 for image recognition\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Build and train the model\n",
        "Demonstrate callbacks, learning rate scheduling, plotting utilities\n",
        "Predict test patterns\n",
        "\n",
        "Dataset: https://www.kaggle.com/c/detect-pneumonia-fall-2020/data\n",
        "\n",
        "*Importing dataset from google drive*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhfTJ8Bh5eo4"
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "import cv2\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "import skimage\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Activation, Concatenate, \\\n",
        "                                    AveragePooling2D, Input, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tqdm import tqdm\n",
        "from skimage.transform import resize\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os as os\n",
        "import time\n",
        "from numpy.linalg import inv, norm\n",
        "from csv import reader\n",
        "np.set_printoptions(suppress=True, precision=3)\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "os.chdir('/content/gdrive/My Drive/Colab Notebooks/')\n",
        "print(os.getcwd())\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20hbTnTCqDh3"
      },
      "source": [
        "Reading Images to Ram **size(150,150)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jRl-Uvuuifz"
      },
      "source": [
        "trainData=\"/content/gdrive/My Drive/Xraydataset/train_images\"\r\n",
        "training_data=[]\r\n",
        "\r\n",
        "\r\n",
        "i=0\r\n",
        "def create_training_data(i):\r\n",
        "  for img in os.listdir(trainData):\r\n",
        "    print(i) \r\n",
        "       \r\n",
        "    with open('/content/gdrive/My Drive/Xraydataset/labels_train.csv', 'r') as read_obj:\r\n",
        "    \r\n",
        "      csv_reader = reader(read_obj)\r\n",
        "   \r\n",
        "      for row in csv_reader:\r\n",
        "        \r\n",
        "        \r\n",
        "        if row[0] == img:\r\n",
        "          class_num=row[1]\r\n",
        "          break       \r\n",
        "          \r\n",
        "        \r\n",
        "         \r\n",
        "          \r\n",
        "    eikona = image.load_img(os.path.join(trainData,img), target_size=(150,150)) #eikona = image.load_img(os.path.join(trainData,img), target_size=(300, 300)) \r\n",
        "    \r\n",
        "    img_array=image.img_to_array(eikona)\r\n",
        "    training_data.append([img_array,class_num])\r\n",
        "    i+=1\r\n",
        "  \r\n",
        "create_training_data(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_snuoBdujdE"
      },
      "source": [
        "x_train=[]\r\n",
        "y_train=[]\r\n",
        "\r\n",
        "for i in range(len(training_data)):\r\n",
        "  x_train.append(training_data[i][0])\r\n",
        "  y_train.append(training_data[i][1])\r\n",
        "  y_train[i]=int(y_train[i])\r\n",
        "training_data.clear()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ_RVDwAuqzm"
      },
      "source": [
        "x_in=Input(shape=[150,150,3])\r\n",
        "x_train=np.asarray(x_train)\r\n",
        "x_train=x_train/255.0\r\n",
        "x_train_mean = np.mean(x_train, axis=0)\r\n",
        "x_train -= x_train_mean\r\n",
        "x_train=np.asarray(x_train)\r\n",
        "y_train=np.asarray(y_train)\r\n",
        "t_train = keras.utils.to_categorical(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3A8-ORlux6k"
      },
      "source": [
        "testData=\"/content/gdrive/My Drive/Xraydataset/test_images\"\r\n",
        "xtest=[] \r\n",
        "for img in os.listdir(testData):\r\n",
        "    eikona = image.load_img(os.path.join(testData,img),target_size=(150, 150)) #(300, 300)) \r\n",
        "    img_array=image.img_to_array(eikona)\r\n",
        "    xtest.append(img_array)  \r\n",
        "xtest=np.asarray(xtest)\r\n",
        "xtest=xtest/255.0\r\n",
        "xtest -= x_train_mean\r\n",
        "t_test = keras.utils.to_categorical(xtest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUPdniMLvSAa"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_train, t_train, test_size=0.33)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQ0f5I_frBrH"
      },
      "source": [
        "Implementing Resnest layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4-LoByH4a90"
      },
      "source": [
        "def resnet_layer(inputs,\r\n",
        "                 num_filters=16,\r\n",
        "                 kernel_size=3,\r\n",
        "                 strides=1,\r\n",
        "                 activation='relu',\r\n",
        "                 batch_normalization=True,\r\n",
        "                 conv_first=True):\r\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\r\n",
        "\r\n",
        "    # Arguments\r\n",
        "        inputs (tensor): input tensor from input image or previous layer\r\n",
        "        num_filters (int): Conv2D number of filters\r\n",
        "        kernel_size (int): Conv2D square kernel dimensions\r\n",
        "        strides (int): Conv2D square stride dimensions\r\n",
        "        activation (string): activation name\r\n",
        "        batch_normalization (bool): whether to include batch normalization\r\n",
        "        conv_first (bool): conv-bn-activation (True) or\r\n",
        "            bn-activation-conv (False)\r\n",
        "\r\n",
        "    # Returns\r\n",
        "        x (tensor): tensor as input to the next layer\r\n",
        "    \"\"\"\r\n",
        "    conv = Conv2D(num_filters,\r\n",
        "                  kernel_size=kernel_size,\r\n",
        "                  strides=strides,\r\n",
        "                  padding='same',\r\n",
        "                  kernel_initializer='he_normal',\r\n",
        "                  kernel_regularizer=l2(1e-4))\r\n",
        "\r\n",
        "    x = inputs\r\n",
        "    if conv_first:\r\n",
        "        x = conv(x)\r\n",
        "        if batch_normalization:\r\n",
        "            x = BatchNormalization()(x)\r\n",
        "        if activation is not None:\r\n",
        "            x = Activation(activation)(x)\r\n",
        "    else:\r\n",
        "        if batch_normalization:\r\n",
        "            x = BatchNormalization()(x)\r\n",
        "        if activation is not None:\r\n",
        "            x = Activation(activation)(x)\r\n",
        "        x = conv(x)\r\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Owq39ML5mlg"
      },
      "source": [
        "def resnet_v1(input_shape, depth, num_classes=3):\r\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\r\n",
        "\r\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\r\n",
        "    Last ReLU is after the shortcut connection.\r\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\r\n",
        "    by a convolutional layer with strides=2, while the number of filters is\r\n",
        "    doubled. Within each stage, the layers have the same number filters and the\r\n",
        "    same number of filters.\r\n",
        "    Features maps sizes:\r\n",
        "    stage 0: 32x32, 16\r\n",
        "    stage 1: 16x16, 32\r\n",
        "    stage 2:  8x8,  64\r\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\r\n",
        "    ResNet20 0.27M\r\n",
        "    ResNet32 0.46M\r\n",
        "    ResNet44 0.66M\r\n",
        "    ResNet56 0.85M\r\n",
        "    ResNet110 1.7M\r\n",
        "\r\n",
        "    # Arguments\r\n",
        "        input_shape (tensor): shape of input image tensor\r\n",
        "        depth (int): number of core convolutional layers\r\n",
        "        num_classes (int): number of classes (3)\r\n",
        "\r\n",
        "    # Returns\r\n",
        "        model (Model): Keras model instance\r\n",
        "    \"\"\"\r\n",
        "    if (depth - 2) % 6 != 0:\r\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\r\n",
        "    # Start model definition.\r\n",
        "    num_filters = 16\r\n",
        "    num_res_blocks = int((depth - 2) / 6)\r\n",
        "\r\n",
        "    inputs = Input(shape=input_shape)\r\n",
        "    x = resnet_layer(inputs=inputs)\r\n",
        "    # Instantiate the stack of residual units\r\n",
        "    for stack in range(3):\r\n",
        "        for res_block in range(num_res_blocks):\r\n",
        "            strides = 1\r\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\r\n",
        "                strides = 2  # downsample\r\n",
        "            y = resnet_layer(inputs=x,\r\n",
        "                             num_filters=num_filters,\r\n",
        "                             strides=strides)\r\n",
        "            y = resnet_layer(inputs=y,\r\n",
        "                             num_filters=num_filters,\r\n",
        "                             activation=None)\r\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\r\n",
        "                # linear projection residual shortcut connection to match\r\n",
        "                # changed dims\r\n",
        "                x = resnet_layer(inputs=x,\r\n",
        "                                 num_filters=num_filters,\r\n",
        "                                 kernel_size=2, ### originally: 1,\r\n",
        "                                 strides=strides,\r\n",
        "                                 activation=None,\r\n",
        "                                 batch_normalization=False)\r\n",
        "            x = keras.layers.add([x, y])\r\n",
        "            #x=keras.layers.add(Dropout(0.5))\r\n",
        "            x = Activation('relu')(x)\r\n",
        "        num_filters *= 2\r\n",
        "\r\n",
        "    # Add classifier on top.\r\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\r\n",
        "\r\n",
        "    x = AveragePooling2D(pool_size=8)(x)#8\r\n",
        "    y = Flatten()(x)\r\n",
        "    outputs = Dense(num_classes,\r\n",
        "                    activation='softmax',            # sigmoid?\r\n",
        "                    kernel_initializer='he_normal')(y)          #GlorotUniform  he_normal\r\n",
        "\r\n",
        "    # Instantiate model.\r\n",
        "    model = Model(inputs=inputs, outputs=outputs)\r\n",
        "    print('Model parameters: {:d}'.format(model.count_params()))\r\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLNYvHCU52SF"
      },
      "source": [
        "def lr_schedule(epoch):\r\n",
        "    \"\"\"Learning Rate Schedule\r\n",
        "\r\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\r\n",
        "    Called automatically every epoch as part of callbacks during training.\r\n",
        "\r\n",
        "    # Arguments\r\n",
        "        epoch (int): The number of epochs\r\n",
        "\r\n",
        "    # Returns\r\n",
        "        lr (float32): learning rate\r\n",
        "    \"\"\"\r\n",
        "    lr = 1e-3\r\n",
        "    if epoch > 180:\r\n",
        "        lr *= 0.5e-3\r\n",
        "    elif epoch > 160:\r\n",
        "        lr *= 1e-3\r\n",
        "    elif epoch > 120:\r\n",
        "        lr *= 1e-2\r\n",
        "    elif epoch > 80:\r\n",
        "        lr *= 1e-1\r\n",
        "    return lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g_3CASb54ws"
      },
      "source": [
        "'''\r\n",
        "Epoch monitoring: Print info at every epoch\r\n",
        "'''\r\n",
        "\r\n",
        "class MyCallback(keras.callbacks.Callback):\r\n",
        "    tstart = None\r\n",
        "    def on_train_begin(self, logs={}):\r\n",
        "        return\r\n",
        "    \r\n",
        "    def on_train_end(self, logs={}):\r\n",
        "        return\r\n",
        "    \r\n",
        "    def on_epoch_begin(self, epoch, logs={}):\r\n",
        "        self.tstart = time.time()\r\n",
        "        print('epoch:{:03d}'.format(epoch+1), end=', ')\r\n",
        "        return\r\n",
        "    \r\n",
        "    def on_epoch_end(self, epoch, logs={}):\r\n",
        "        print('loss:{:8.6f}, acc:{:8.6f},  val_loss:{:8.6f}, val_acc:{:8.6f},  val_acc-acc = {:5.2f}%,  lr:{:0.6f}  [{:0.2f} sec]'.format(\r\n",
        "                logs.get('loss'), logs.get('acc'),\r\n",
        "                logs.get('val_loss'), logs.get('val_acc'),\r\n",
        "                100*(logs.get('val_acc')-logs.get('acc')),\r\n",
        "                K.eval(self.model.optimizer.lr),\r\n",
        "                time.time()-self.tstart))\r\n",
        "        return\r\n",
        "    \r\n",
        "    def on_batch_begin(self, batch, logs={}):\r\n",
        "        return\r\n",
        "    \r\n",
        "    def on_batch_end(self, batch, logs={}):\r\n",
        "        return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL5l-JVS57Yl"
      },
      "source": [
        "depth=50\r\n",
        "input_shape = x_train.shape[1:]\r\n",
        "model = resnet_v1(input_shape=input_shape, depth=depth)\r\n",
        "    \r\n",
        "model.compile(loss=\"categorical_crossentropy\",\r\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\r\n",
        "              metrics=['acc'])\r\n",
        "#model.summary()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVKvJLWB6cWK"
      },
      "source": [
        "plot_model(model, show_shapes=True, dpi=48)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvfxakUZ6eyf"
      },
      "source": [
        "'''\r\n",
        "The Model object has the following attributes\r\n",
        "['_uses_inputs_arg', 'inputs', 'outputs', 'name', 'trainable',\r\n",
        "'_is_compiled', '_expects_training_arg', '_initial_weights', 'supports_masking', 'optimizer',\r\n",
        "'_updates', '_losses', '_per_input_losses', '_per_input_updates', '_layers',\r\n",
        "'_outbound_nodes', '_inbound_nodes', '_compute_previous_mask', '_built', '_is_graph_network',\r\n",
        "'_input_layers', '_output_layers', '_input_coordinates', '_output_coordinates', '_output_mask_cache',\r\n",
        "'_output_tensor_cache', '_output_shape_cache', '_network_nodes', '_nodes_by_depth', '_layers_by_depth',\r\n",
        "'input_names', 'output_names', '_feed_input_names', '_feed_inputs', '_feed_input_shapes',\r\n",
        "'loss', 'metrics', 'loss_weights', 'sample_weight_mode', 'weighted_metrics',\r\n",
        "'loss_functions', '_feed_outputs', '_feed_output_names', '_feed_output_shapes', '_feed_loss_fns',\r\n",
        "'targets', '_feed_targets', 'sample_weight_modes', '_feed_sample_weight_modes', 'metrics_names',\r\n",
        "'metrics_tensors', 'metrics_updates', 'stateful_metric_names', 'stateful_metric_functions', 'total_loss',\r\n",
        "'sample_weights', '_feed_sample_weights', '_function_kwargs', 'train_function', 'test_function',\r\n",
        "'predict_function', '_collected_trainable_weights', 'history', 'stop_training'])\r\n",
        "'''\r\n",
        "for layer in range(len(model._layers)):\r\n",
        "    layer_obj = model._layers[layer]\r\n",
        "    print('{}'.format(layer_obj.name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiUBraVAk2nA"
      },
      "source": [
        "# Training parameters\r\n",
        "batch_size =16#32  # orig paper trained all networks with batch_size=128 me 128 crusharei\r\n",
        "epochs = 20#0\r\n",
        "\r\n",
        "# Prepare model model saving directory.\r\n",
        "model_name = 'resnet50F1-e{epoch:04d}-loss{loss:.3f}-acc{acc:.3f}-valloss{val_loss:.3f}-valacc{val_acc:.3f}.h5'\r\n",
        "if not os.path.isdir(save_dir):\r\n",
        "    os.makedirs(save_dir)\r\n",
        "filepath = os.path.join(save_dir, model_name)\r\n",
        "\r\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\r\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\r\n",
        "                             monitor='val_acc',\r\n",
        "                             verbose=1,\r\n",
        "                             save_best_only=True)\r\n",
        "\r\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\r\n",
        "\r\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\r\n",
        "                               cooldown=0,\r\n",
        "                               patience=5,\r\n",
        "                               min_lr=0.5e-6)\r\n",
        "\r\n",
        "# This will do preprocessing and realtime data augmentation:\r\n",
        "datagen = ImageDataGenerator(\r\n",
        "    # set input mean to 0 over the dataset\r\n",
        "    featurewise_center=True,\r\n",
        "    # set each sample mean to 0\r\n",
        "    samplewise_center=True,\r\n",
        "    # divide inputs by std of dataset\r\n",
        "    featurewise_std_normalization=True,#true\r\n",
        "    # divide each input by its std\r\n",
        "    samplewise_std_normalization=True,\r\n",
        "    # apply ZCA whitening\r\n",
        "    zca_whitening=False, #true???\r\n",
        "    # epsilon for ZCA whitening\r\n",
        "    zca_epsilon=1e-06,#05?\r\n",
        "    # randomly rotate images in the range (deg 0 to 180)\r\n",
        "    rotation_range=0.,\r\n",
        "    # randomly shift images horizontally\r\n",
        "    width_shift_range=0.,#0.1\r\n",
        "    # randomly shift images vertically\r\n",
        "    height_shift_range=0.,#0.1\r\n",
        "    # set range for random shear\r\n",
        "    shear_range=0.,\r\n",
        "    # set range for random zoom\r\n",
        "    zoom_range=0., \r\n",
        "    # set range for random channel shifts\r\n",
        "    channel_shift_range=0,\r\n",
        "    # set mode for filling points outside the input boundaries\r\n",
        "    fill_mode='nearest',\r\n",
        "    # value used for fill_mode = \"constant\"\r\n",
        "    cval=0.,\r\n",
        "    # randomly flip images\r\n",
        "    horizontal_flip=False,#True\r\n",
        "    # randomly flip images\r\n",
        "    vertical_flip=False,\r\n",
        "    # set rescaling factor (applied before any other transformation)\r\n",
        "    rescale=None,#none\r\n",
        "    # set function that will be applied on each input\r\n",
        "    preprocessing_function=None,\r\n",
        "    # image data format, either \"channels_first\" or \"channels_last\"\r\n",
        "    data_format=None,\r\n",
        "    # fraction of images reserved for validation (strictly between 0 and 1)\r\n",
        "    validation_split=0.0)\r\n",
        "\r\n",
        "# Compute quantities required for featurewise normalization\r\n",
        "# (std, mean, and principal components if ZCA whitening is applied).\r\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTfRVxg66i10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4395b44e-f14e-455a-eb1c-a5b16b7cd653"
      },
      "source": [
        "\r\n",
        "#tf.Variable  v = tf.Variable(np.zeros(shape=shape, dtype=dtype), name=name)\r\n",
        "# Fit the model on the batches generated by datagen.flow().(datagen.flow(xtrain, t_train, batch_size=batch_size),   (datagen.flow(xtrain, t_train, batch_size=batch_size)              (xtrain, t_train, batch_size=batch_size\r\n",
        "history = model.fit(x_train, y_train, batch_size=batch_size,  \r\n",
        "                               validation_data=(x_test, y_test),#xtrain, t_train          xtest, t_test\r\n",
        "                               epochs=epochs, verbose=0, workers=4,#verbose=0 workers=4\r\n",
        "                               steps_per_epoch = int(x_train.shape[0]/batch_size),class_weight={0: .9837, 1: .5394, 2: 1.0},\r\n",
        "                               callbacks=[lr_reducer, lr_scheduler, MyCallback(), checkpoint])#lr_scheduler\r\n",
        "\r\n",
        "\r\n",
        "# Score trained model.\r\n",
        "#scores = model.evaluate(xtest, y_test, verbose=1)\r\n",
        "print('Test loss:', scores[0])\r\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:001, WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1849s vs `on_train_batch_end` time: 0.2699s). Check your callbacks.\n",
            "loss:0.304990, acc:0.936538,  val_loss:2.077518, val_acc:0.346952,  val_acc-acc = -58.96%,  lr:0.001000  [98.42 sec]\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.77302\n",
            "epoch:002, loss:0.229475, acc:0.977521,  val_loss:2.283374, val_acc:0.448768,  val_acc-acc = -52.88%,  lr:0.001000  [97.98 sec]\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.77302\n",
            "epoch:003, loss:0.198916, acc:0.990366,  val_loss:2.018332, val_acc:0.488975,  val_acc-acc = -50.14%,  lr:0.001000  [98.03 sec]\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.77302\n",
            "epoch:004, loss:0.186410, acc:0.996146,  val_loss:1.335735, val_acc:0.707523,  val_acc-acc = -28.86%,  lr:0.001000  [97.95 sec]\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.77302\n",
            "epoch:005, loss:0.184342, acc:0.991972,  val_loss:1.701018, val_acc:0.712062,  val_acc-acc = -27.99%,  lr:0.001000  [97.77 sec]\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.77302\n",
            "epoch:006, loss:0.249693, acc:0.961785,  val_loss:1.361798, val_acc:0.743191,  val_acc-acc = -21.86%,  lr:0.001000  [97.75 sec]\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.77302\n",
            "epoch:007, loss:0.237180, acc:0.968208,  val_loss:1.465037, val_acc:0.719196,  val_acc-acc = -24.90%,  lr:0.001000  [97.76 sec]\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.77302\n",
            "epoch:008, loss:0.208615, acc:0.980090,  val_loss:1.439979, val_acc:0.723735,  val_acc-acc = -25.64%,  lr:0.001000  [97.83 sec]\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.77302\n",
            "epoch:009, loss:0.230224, acc:0.975915,  val_loss:1.167123, val_acc:0.740597,  val_acc-acc = -23.53%,  lr:0.001000  [97.72 sec]\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.77302\n",
            "epoch:010, loss:0.200395, acc:0.985549,  val_loss:1.485193, val_acc:0.723735,  val_acc-acc = -26.18%,  lr:0.001000  [97.85 sec]\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.77302\n",
            "epoch:011, loss:0.209689, acc:0.979448,  val_loss:1.594169, val_acc:0.694553,  val_acc-acc = -28.49%,  lr:0.001000  [98.02 sec]\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.77302\n",
            "epoch:012, loss:0.208517, acc:0.983622,  val_loss:1.800459, val_acc:0.733463,  val_acc-acc = -25.02%,  lr:0.001000  [98.10 sec]\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.77302\n",
            "epoch:013, loss:0.208751, acc:0.980090,  val_loss:1.367761, val_acc:0.709468,  val_acc-acc = -27.06%,  lr:0.001000  [98.14 sec]\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.77302\n",
            "epoch:014, loss:0.196493, acc:0.985228,  val_loss:1.453589, val_acc:0.736706,  val_acc-acc = -24.85%,  lr:0.000316  [97.93 sec]\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.77302\n",
            "epoch:015, loss:0.194782, acc:0.986834,  val_loss:1.615047, val_acc:0.739300,  val_acc-acc = -24.75%,  lr:0.001000  [98.07 sec]\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.77302\n",
            "epoch:016, loss:0.197708, acc:0.983943,  val_loss:1.557482, val_acc:0.701686,  val_acc-acc = -28.23%,  lr:0.001000  [97.89 sec]\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.77302\n",
            "epoch:017, loss:0.210089, acc:0.977200,  val_loss:1.160285, val_acc:0.765240,  val_acc-acc = -21.20%,  lr:0.001000  [97.98 sec]\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.77302\n",
            "epoch:018, loss:0.181595, acc:0.990687,  val_loss:1.713646, val_acc:0.708171,  val_acc-acc = -28.25%,  lr:0.001000  [97.96 sec]\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.77302\n",
            "epoch:019, loss:0.165497, acc:0.997431,  val_loss:1.497103, val_acc:0.755512,  val_acc-acc = -24.19%,  lr:0.001000  [97.88 sec]\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.77302\n",
            "epoch:020, loss:0.193513, acc:0.982980,  val_loss:1.363482, val_acc:0.732815,  val_acc-acc = -25.02%,  lr:0.001000  [97.77 sec]\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.77302\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-9cb66a8bc33c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Score trained model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#scores = model.evaluate(xtest, y_test, verbose=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'scores' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiZZSRTZVyOZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc967189-8a73-496f-86ef-dd887ace9578"
      },
      "source": [
        "y1=model.predict(X_test)\r\n",
        "y=np.argmax(y1, axis=-1)\r\n",
        "y=np.transpose(y)\r\n",
        "print(\"y1:\",y1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y1: [[0.28  0.394 0.326]\n",
            " [0.273 0.399 0.328]\n",
            " [0.287 0.407 0.306]\n",
            " ...\n",
            " [0.272 0.414 0.314]\n",
            " [0.279 0.406 0.315]\n",
            " [0.28  0.406 0.314]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtveDZrMhRbG",
        "outputId": "cd200f95-23ea-41ab-dcf3-7edfe1c3f8ae"
      },
      "source": [
        "print(\"y:\",y)\r\n",
        "#print(\"x:\",x)\r\n",
        "import pandas as pd\r\n",
        "res = pd.DataFrame(y)\r\n",
        "#res.index = X_test.index # its important for comparison\r\n",
        "res.columns = [\"prediction\"]\r\n",
        "res.to_csv(\"/content/prediction_results.csv\")\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y: [1 1 1 ... 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38PtMPGJ6kx3"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "plt.figure(figsize=(10,8))\r\n",
        "plt.plot(history.history['acc'])\r\n",
        "plt.plot(history.history['val_acc'])\r\n",
        "plt.xlabel('Epochs')\r\n",
        "plt.ylabel('%')\r\n",
        "plt.legend(('acc','val-acc'))\r\n",
        "plt.grid(b=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}